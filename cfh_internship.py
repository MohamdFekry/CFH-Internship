# -*- coding: utf-8 -*-
"""CFH Internship.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14nvcGz8_Pcal6sh2OUCQVaX_S0ta4wo1

# Training models on the first company's dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

df = pd.read_csv('/content/EGX_DLY_COMI, 1D.csv')

# seeing the data
print(df.head())   # the time is represented as timestamp

# data info
print(df.info())

# statistics of the data
print(df.describe())

# we don't need to handle missing values or scaling here, since info() showed there are no Null values here, and
# descibe() showed that the scales of the 'open', 'high', and 'low' are similar
# however, we can check for outliers

plt.figure(figsize=(10, 6))

plt.subplot(1, 3, 1)
plt.hist(df['open'], bins=20, color='lightgreen', edgecolor='black')
plt.xlabel('open')
plt.ylabel('Frequency')
plt.title('Histogram of Open')

plt.subplot(1, 3, 2)
plt.hist(df['high'], bins=20, color='salmon', edgecolor='black')
plt.xlabel('high')
plt.ylabel('Frequency')
plt.title('Histogram of High')

plt.subplot(1, 3, 3)
plt.hist(df['low'], bins=20, color='skyblue', edgecolor='black')
plt.xlabel('low')
plt.ylabel('Frequency')
plt.title('Histogram of Low')

plt.tight_layout()
plt.show()

# the histograms along with the output of describe() show that
# most of the prices are below 35

mean_open = df['open'].mean()
std_open = df['open'].std()

mean_high = df['high'].mean()
std_high = df['high'].std()

mean_low = df['low'].mean()
std_low = df['low'].std()

# getting outliers for the open, high, and low columns
outliers_open = df[(df['open'] < mean_open - 2 * std_open) | (df['open'] > mean_open + 2 * std_open)]
outliers_high = df[(df['high'] < mean_high - 2 * std_high) | (df['high'] > mean_high + 2 * std_high)]
outliers_low = df[(df['low'] < mean_low - 2 * std_low) | (df['low'] > mean_low + 2 * std_low)]

print("Outliers in 'open' column:", len(outliers_open))
print("Outliers in 'high' column:", len(outliers_high))
print("Outliers in 'low' column:", len(outliers_low))

# I decided not to handle the outliers because they are low in quantity and in gravity
# They also haven't decreased the error values significantly after removing them

#outliers = pd.concat([outliers_open, outliers_high, outliers_low])

#df = df.drop(outliers.index)
#print(df.describe())

df['time'] = pd.to_datetime(df['time'])

# Plot the time series of closing prices
plt.figure(figsize=(10, 6))
plt.plot(df['time'], df['close'], color='blue')
plt.title('Time Series of Closing Prices')
plt.xlabel('Time')
plt.ylabel('Closing Price')
plt.grid(True)
plt.show()

# the time series graph shows that the closing price increases with the time that
# the stock is available which could mean that these are winning stocks

correlation_matrix = df[['open', 'high', 'low', 'close']].corr()

# Print the correlation matrix
print("Correlation Matrix:")
print(correlation_matrix)

# Extract the correlation coefficients between 'Open', 'High', and 'Low' columns with 'Close' column
open_close_corr = correlation_matrix.loc['open', 'close']
high_close_corr = correlation_matrix.loc['high', 'close']
low_close_corr = correlation_matrix.loc['low', 'close']

# Print the correlation coefficients
print("\nCorrelation between Open and Close:", open_close_corr)
print("Correlation between High and Close:", high_close_corr)
print("Correlation between Low and Close:", low_close_corr)

# Handling the 'time' column
print('Years:', pd.to_datetime(df['time']).dt.year.unique())
print('Months:', pd.to_datetime(df['time']).dt.month.unique())
print('Days:', pd.to_datetime(df['time']).dt.day.unique())
print('Hours:', pd.to_datetime(df['time']).dt.hour.unique())
print('Minutes:', pd.to_datetime(df['time']).dt.minute.unique())
print('Seconds:', pd.to_datetime(df['time']).dt.second.unique())

# it seems the dataset entries was all in the same hour and minute
# so we need to include only the second and part of the second of the opening time of the stock price
print('Microseconds:', pd.to_datetime(df['time']).dt.microsecond.unique())
print('Numbe of unique microseconds:', pd.to_datetime(df['time']).dt.microsecond.nunique())

df['second'] = pd.to_datetime(df['time']).dt.second
df['microsecond'] = pd.to_datetime(df['time']).dt.microsecond
print(df.head())

# Now to split the data to training and testing, and input an output
X = df[['second', 'microsecond', 'open', 'high', 'low']]
Y = df['close']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=42)

# choosing the models
model_1 = LinearRegression()
model_2 = GradientBoostingRegressor()
model_3 = MLPRegressor()

model_1.fit(X_train, Y_train)
Y_pred = model_1.predict(X_test)
print("Linear Regressor mae:", mean_absolute_error(Y_test, Y_pred))
print("Linear Regressor mad:", np.mean(np.abs(Y_test - Y_pred)))
print("Linear Regressor mse:", mean_squared_error(Y_test, Y_pred))

model_2.fit(X_train, Y_train)
Y_pred = model_2.predict(X_test)
print("Gradient Boosting Regressor mae:", mean_absolute_error(Y_test, Y_pred))
print("Gradient Boosting Regressor mad:", np.mean(np.abs(Y_test - Y_pred)))
print("Gradient Boosting Regressor mse:", mean_squared_error(Y_test, Y_pred))

model_3.fit(X_train, Y_train)
Y_pred = model_3.predict(X_test)
print("Multi-layer Perceptron Regressor mae:", mean_absolute_error(Y_test, Y_pred))
print("Multi-layer Perceptron mad:", np.mean(np.abs(Y_test - Y_pred)))
print("Multi-layer Perceptron mse:", mean_squared_error(Y_test, Y_pred))

"""# Predicting another company's prices"""

# The results above show that the Linear regressor is best for this task
# We can try to predict another company's closing price with it now
df2 = pd.read_csv('/content/EGX_DLY_ISPH, 1D.csv')
df2['second'] = pd.to_datetime(df2['time']).dt.second
df2['microsecond'] = pd.to_datetime(df2['time']).dt.microsecond
X2 = df2[['second', 'microsecond', 'open', 'high', 'low']]
Y2 = df2['close']

Y_pred2 = model_1.predict(X2)
print("Performance on EGX_DLY_ISPH stocks")
print("Linear Regressor mae:", mean_absolute_error(Y2, Y_pred2))
print("Linear Regressor mad:", np.mean(np.abs(Y2 - Y_pred2)))
print("Linear Regressor mse:", mean_squared_error(Y2, Y_pred2))

